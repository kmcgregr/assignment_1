{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MapReduce Code Example</h1>\n",
    "\n",
    "The following code is very similar to what you will be provided for assignment 1.\n",
    "\n",
    "Recall, we have two scripts, the mapper and reducer. The function of the mapper is simply to output each word in the text, followed by the number 1. The mapper takes this output and adds up all the number 1's for each of the same word.\n",
    "\n",
    "\n",
    "Lets walk through the mapper code first. Take your time examining this code. The comments will provide details on what each line does. \n",
    "\n",
    "It is not essential that you understand each line, however, a thorough understanding of this algorithm will help you in understanding MapReduce as a whole.\n",
    "\n",
    "<em>Note: The mapper and reducer code has been slightly modified to read from the provided textfiles (input.txt and output.txt). In the code that will be run by Hadoop, we will be reading from 'stdin' instead. However, this is a minor detail and the majority of the code is unchanged.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The Mapper</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\t1\n",
      "Sauce\t1\n",
      "Red\t1\n",
      "Door\t1\n",
      "To\t1\n",
      "Who\t1\n",
      "Who\t1\n",
      "Red\t1\n",
      "Cat\t1\n",
      "Sauce\t1\n",
      "To\t1\n",
      "Door\t1\n",
      "Cat\t1\n",
      "Apple\t1\n",
      "Door\t1\n"
     ]
    }
   ],
   "source": [
    "#Open the textfile (this is not required in the actual Hadoop implementation since we will just be reading from stdin)\n",
    "input_file = open(\"input.txt\", \"r\")\n",
    "\n",
    "#For loop - for each line in the textfile, remove the whitespaces and split the line into individual words.\n",
    "#Note: This For Loop contains a nested For Loop at the bottom.\n",
    "for line in input_file:\n",
    "\n",
    "    #--- remove leading and trailing whitespace---\n",
    "    line=line.strip()\n",
    "    #--- split the line into words ---\n",
    "    words=line.split()\n",
    "        \n",
    "    #For Loop - for each word in the line, print the word, a tab, and the number 1\n",
    "    for word in words:\n",
    "        print (\"%s\\t%s\" %(word,\"1\"))\n",
    "        \n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see all we are doing is printing each word and the number one next to it.\n",
    "\n",
    "Note: You can check the output.txt file to view these results. That file will become the input for the reducer in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2>The Reducer</h2>\n",
    "<br>\n",
    "Next let's look at the Reducer code (modified to read from the provided output.txt file)\n",
    "\n",
    "This code is a bit more dense, but all we are doing is taking the list generated from the mapper and adding up the numbers of words that are the same. This is also called aggregation.\n",
    "\n",
    "The main feature of this code is that it uses a Python dictionary and a try statement to perform the aggregation. It does this by first assuming (\"try:\") the word is already in the dictionary and attempts to add 1 to the value. \n",
    "\n",
    "If this generates an error (\"except:\"), it means the word is not yet in the dictionary. If the error is generated, it adds the word to the dictionary along with the value 1.\n",
    "\n",
    "The following comments provide further detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\t2\n",
      "Sauce\t2\n",
      "Red\t2\n",
      "Door\t3\n",
      "To\t2\n",
      "Who\t2\n",
      "Cat\t2\n"
     ]
    }
   ],
   "source": [
    "#Open the textfile (this is not required in the actual Hadoop implementation because we are reading in from stdin)\n",
    "#Note this textfile simply contains the output from the mapper as generated above\n",
    "mapper_input = open(\"output.txt\", 'r')\n",
    "\n",
    "#Create an empty dictionary called word2count\n",
    "word2count={}\n",
    "\n",
    "#For loop - for each line in the textfile, extract the words from each line and save it into a variable called word\n",
    "for line in mapper_input:\n",
    "    #Remove leading and trailing whitespaces\n",
    "    line=line.strip()\n",
    "    #Save the word to a variable called word. Also, save the number 1 to a variable called count\n",
    "    word,count=line.split('\\t',1)\n",
    "    \n",
    "    #Convert count (currently a string) to integer\n",
    "    count=int(count)\n",
    " \n",
    "    \n",
    "    #Try Block: Try adding the count variable to the word in the dictionary. \n",
    "    #The exception will be generated if that word does not exist yet in the dictionary. \n",
    "    #In that case, the code under 'except:' will add the word to the dictionary and set it's value to 1.\n",
    "    try:\n",
    "        #The word is already in the dictionary and we are just adding 1 to the value\n",
    "        word2count[word]=word2count[word]+count\n",
    "    except:\n",
    "        #The word is not in the dictionary and we are adding it as a new entry and making the value 1\n",
    "        word2count[word]=count\n",
    "        \n",
    "#For each word in the dictionary, print the word, a tab, then the aggregated count.\n",
    "#Note: they are unsorted\n",
    "for word in word2count.keys():\n",
    "    print (\"%s\\t%s\"%(word,word2count[word]))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
